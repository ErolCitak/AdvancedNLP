{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Input, LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "import gensim\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some config\n",
    "BATCH_SIZE = 64  # Batch size for training.\n",
    "EPOCHS = 15  # Number of epochs to train for.\n",
    "LATENT_DIM = 512  # Latent dimensionality of the encoding space.\n",
    "NUM_SAMPLES = 20000  # Number of samples to train on.\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_NUM_WORDS = 25000\n",
    "EMBEDDING_DIM = 300  # embedding dimension for word embedding which is given at encoder training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "input_texts = []\n",
    "target_texts = [] # with end token\n",
    "target_texts_inputs = [] # with start token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for line in open(\"C://Users//dtecitak//Desktop//AdvancedNLP-master//Data//MT//tur.txt\", encoding=\"utf-8\"):\n",
    "    count += 1\n",
    "    \n",
    "    if count > NUM_SAMPLES:\n",
    "        break\n",
    "    \n",
    "    if '\\t' not in line:\n",
    "        continue\n",
    "    \n",
    "    input_text, output = line.rstrip().split('\\t')[:2]\n",
    "    \n",
    "    target_text = output + ' <eos>'\n",
    "    target_text_input = '<sos> '+ output\n",
    "    \n",
    "    input_texts.append(input_text) # Erol is a good boy\n",
    "    target_texts.append(target_text) # Erol iyi bir çocuktur <eos>, decoder output\n",
    "    target_texts_inputs.append(target_text_input) # <sos> Erol iyi bir çocuktur, decoder input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Encoder Sample Number:  20000\n",
      "Training Decoder Output Sample Number:  20000\n",
      "Training Decoder Input Sample Number:  20000\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Encoder Sample Number: \", len(input_texts))\n",
    "print(\"Training Decoder Output Sample Number: \", len(target_texts))\n",
    "print(\"Training Decoder Input Sample Number: \", len(target_texts_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run!\n",
      "Kaç! <eos>\n",
      "<sos> Kaç!\n"
     ]
    }
   ],
   "source": [
    "print(input_texts[0])\n",
    "print(target_texts[0])\n",
    "print(target_texts_inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4668 unique input tokens.\n",
      "Max sentence length for Input:  7\n"
     ]
    }
   ],
   "source": [
    "#Tokenization Input\n",
    "\n",
    "# It divides a sentence into the corresponding list of word\n",
    "# Then it converts the words to integers\n",
    "tokenizer_inputs = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer_inputs.fit_on_texts(input_texts)\n",
    "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)\n",
    "\n",
    "# get the word to index mapping for input language\n",
    "word2idx_inputs = tokenizer_inputs.word_index\n",
    "print('Found %s unique input tokens.' % len(word2idx_inputs))\n",
    "\n",
    "# determine maximum length input sequence\n",
    "max_len_input = max(len(s) for s in input_sequences)\n",
    "print(\"Max sentence length for Input: \",max_len_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tom': 1,\n",
       " 'i': 2,\n",
       " 'you': 3,\n",
       " 'a': 4,\n",
       " 'is': 5,\n",
       " 'the': 6,\n",
       " 'to': 7,\n",
       " 'it': 8,\n",
       " \"i'm\": 9,\n",
       " 'was': 10,\n",
       " 'do': 11,\n",
       " 'we': 12,\n",
       " 'that': 13,\n",
       " 'my': 14,\n",
       " 'me': 15,\n",
       " 'this': 16,\n",
       " 'are': 17,\n",
       " 'have': 18,\n",
       " 'your': 19,\n",
       " \"don't\": 20,\n",
       " 'not': 21,\n",
       " 'can': 22,\n",
       " 'did': 23,\n",
       " 'in': 24,\n",
       " 'be': 25,\n",
       " 'what': 26,\n",
       " 'he': 27,\n",
       " \"it's\": 28,\n",
       " 'want': 29,\n",
       " 'here': 30,\n",
       " 'like': 31,\n",
       " 'has': 32,\n",
       " 'on': 33,\n",
       " \"tom's\": 34,\n",
       " 'go': 35,\n",
       " \"i'll\": 36,\n",
       " 'why': 37,\n",
       " 'how': 38,\n",
       " 'very': 39,\n",
       " 'need': 40,\n",
       " 'all': 41,\n",
       " 'for': 42,\n",
       " 'they': 43,\n",
       " 'us': 44,\n",
       " \"can't\": 45,\n",
       " \"you're\": 46,\n",
       " 'at': 47,\n",
       " 'know': 48,\n",
       " 'now': 49,\n",
       " 'get': 50,\n",
       " 'help': 51,\n",
       " \"isn't\": 52,\n",
       " 'his': 53,\n",
       " 'good': 54,\n",
       " 'of': 55,\n",
       " \"that's\": 56,\n",
       " 'got': 57,\n",
       " 'with': 58,\n",
       " 'up': 59,\n",
       " 'will': 60,\n",
       " 'no': 61,\n",
       " 'so': 62,\n",
       " \"didn't\": 63,\n",
       " 'were': 64,\n",
       " \"we're\": 65,\n",
       " 'just': 66,\n",
       " 'an': 67,\n",
       " 'too': 68,\n",
       " 'one': 69,\n",
       " 'who': 70,\n",
       " 'love': 71,\n",
       " 'mary': 72,\n",
       " 'there': 73,\n",
       " 'home': 74,\n",
       " 'out': 75,\n",
       " 'see': 76,\n",
       " 'where': 77,\n",
       " 'she': 78,\n",
       " 'had': 79,\n",
       " 'work': 80,\n",
       " 'look': 81,\n",
       " 'car': 82,\n",
       " 'never': 83,\n",
       " 'give': 84,\n",
       " 'am': 85,\n",
       " \"let's\": 86,\n",
       " 'must': 87,\n",
       " 'come': 88,\n",
       " 'still': 89,\n",
       " 'happy': 90,\n",
       " 'busy': 91,\n",
       " 'should': 92,\n",
       " \"aren't\": 93,\n",
       " \"wasn't\": 94,\n",
       " \"won't\": 95,\n",
       " 'eat': 96,\n",
       " 'some': 97,\n",
       " 'back': 98,\n",
       " 'stop': 99,\n",
       " 'stay': 100,\n",
       " 'tell': 101,\n",
       " 'really': 102,\n",
       " 'them': 103,\n",
       " \"i've\": 104,\n",
       " 'our': 105,\n",
       " \"what's\": 106,\n",
       " \"they're\": 107,\n",
       " 'bad': 108,\n",
       " 'take': 109,\n",
       " 'does': 110,\n",
       " 'lot': 111,\n",
       " 'leave': 112,\n",
       " 'talk': 113,\n",
       " 'think': 114,\n",
       " 'time': 115,\n",
       " 'please': 116,\n",
       " 'going': 117,\n",
       " 'let': 118,\n",
       " 'right': 119,\n",
       " 'everyone': 120,\n",
       " 'could': 121,\n",
       " 'such': 122,\n",
       " 'well': 123,\n",
       " 'today': 124,\n",
       " 'job': 125,\n",
       " 'call': 126,\n",
       " 'money': 127,\n",
       " 'dog': 128,\n",
       " 'and': 129,\n",
       " 'ready': 130,\n",
       " 'even': 131,\n",
       " 'again': 132,\n",
       " 'may': 133,\n",
       " 'jerk': 134,\n",
       " \"he's\": 135,\n",
       " 'alone': 136,\n",
       " 'wanted': 137,\n",
       " 'late': 138,\n",
       " 'would': 139,\n",
       " 'wait': 140,\n",
       " 'lost': 141,\n",
       " 'left': 142,\n",
       " 'made': 143,\n",
       " 'try': 144,\n",
       " 'about': 145,\n",
       " 'new': 146,\n",
       " 'big': 147,\n",
       " 'went': 148,\n",
       " 'off': 149,\n",
       " 'saw': 150,\n",
       " 'hate': 151,\n",
       " 'book': 152,\n",
       " 'said': 153,\n",
       " 'knows': 154,\n",
       " \"we'll\": 155,\n",
       " 'man': 156,\n",
       " 'day': 157,\n",
       " 'hard': 158,\n",
       " 'came': 159,\n",
       " 'hungry': 160,\n",
       " 'old': 161,\n",
       " 'life': 162,\n",
       " 'feel': 163,\n",
       " 'say': 164,\n",
       " 'boston': 165,\n",
       " 'problem': 166,\n",
       " 'done': 167,\n",
       " \"who's\": 168,\n",
       " 'him': 169,\n",
       " 'find': 170,\n",
       " 'win': 171,\n",
       " 'her': 172,\n",
       " 'yet': 173,\n",
       " 'tired': 174,\n",
       " 'buy': 175,\n",
       " 'told': 176,\n",
       " 'only': 177,\n",
       " 'make': 178,\n",
       " 'wrong': 179,\n",
       " 'much': 180,\n",
       " 'house': 181,\n",
       " 'by': 182,\n",
       " 'down': 183,\n",
       " 'these': 184,\n",
       " 'more': 185,\n",
       " 'ate': 186,\n",
       " 'fast': 187,\n",
       " 'room': 188,\n",
       " 'way': 189,\n",
       " 'long': 190,\n",
       " 'likes': 191,\n",
       " 'play': 192,\n",
       " 'when': 193,\n",
       " 'ask': 194,\n",
       " 'live': 195,\n",
       " 'bought': 196,\n",
       " 'door': 197,\n",
       " 'doing': 198,\n",
       " 'wants': 199,\n",
       " 'school': 200,\n",
       " \"where's\": 201,\n",
       " 'tried': 202,\n",
       " 'read': 203,\n",
       " 'looked': 204,\n",
       " 'nice': 205,\n",
       " 'everybody': 206,\n",
       " 'ok': 207,\n",
       " 'sick': 208,\n",
       " 'kept': 209,\n",
       " 'anyone': 210,\n",
       " 'hope': 211,\n",
       " 'keep': 212,\n",
       " 'died': 213,\n",
       " 'nothing': 214,\n",
       " 'anything': 215,\n",
       " 'idea': 216,\n",
       " 'been': 217,\n",
       " 'fun': 218,\n",
       " 'speak': 219,\n",
       " 'believe': 220,\n",
       " 'looks': 221,\n",
       " 'show': 222,\n",
       " 'took': 223,\n",
       " '30': 224,\n",
       " 'plan': 225,\n",
       " 'meet': 226,\n",
       " 'both': 227,\n",
       " 'gave': 228,\n",
       " 'put': 229,\n",
       " 'pretty': 230,\n",
       " 'great': 231,\n",
       " \"i'd\": 232,\n",
       " 'angry': 233,\n",
       " 'hat': 234,\n",
       " 'yourself': 235,\n",
       " 'already': 236,\n",
       " 'away': 237,\n",
       " 'over': 238,\n",
       " 'open': 239,\n",
       " 'felt': 240,\n",
       " 'soon': 241,\n",
       " 'three': 242,\n",
       " 'quite': 243,\n",
       " 'run': 244,\n",
       " 'die': 245,\n",
       " 'french': 246,\n",
       " 'people': 247,\n",
       " 'watch': 248,\n",
       " 'hot': 249,\n",
       " 'nobody': 250,\n",
       " 'found': 251,\n",
       " 'loves': 252,\n",
       " 'as': 253,\n",
       " 'won': 254,\n",
       " 'trust': 255,\n",
       " 'always': 256,\n",
       " 'better': 257,\n",
       " 'guy': 258,\n",
       " 'two': 259,\n",
       " 'rich': 260,\n",
       " 'easy': 261,\n",
       " 'cat': 262,\n",
       " 'father': 263,\n",
       " 'any': 264,\n",
       " 'needs': 265,\n",
       " 'hair': 266,\n",
       " 'name': 267,\n",
       " 'hurt': 268,\n",
       " 'use': 269,\n",
       " 'friend': 270,\n",
       " 'water': 271,\n",
       " 'wife': 272,\n",
       " \"doesn't\": 273,\n",
       " \"we've\": 274,\n",
       " 'tv': 275,\n",
       " 'sure': 276,\n",
       " 'paid': 277,\n",
       " 'bed': 278,\n",
       " 'wine': 279,\n",
       " 'used': 280,\n",
       " 'safe': 281,\n",
       " 'sleep': 282,\n",
       " 'free': 283,\n",
       " 'crazy': 284,\n",
       " 'cold': 285,\n",
       " 'change': 286,\n",
       " 'remember': 287,\n",
       " 'coffee': 288,\n",
       " 'those': 289,\n",
       " 'agree': 290,\n",
       " 'sing': 291,\n",
       " 'bit': 292,\n",
       " 'beer': 293,\n",
       " 'drive': 294,\n",
       " 'swim': 295,\n",
       " 'cry': 296,\n",
       " 'bag': 297,\n",
       " 'first': 298,\n",
       " 'own': 299,\n",
       " 'phone': 300,\n",
       " 'fat': 301,\n",
       " 'broke': 302,\n",
       " 'helped': 303,\n",
       " 'last': 304,\n",
       " 'son': 305,\n",
       " 'turn': 306,\n",
       " 'fight': 307,\n",
       " 'met': 308,\n",
       " 'enough': 309,\n",
       " 'from': 310,\n",
       " 'lucky': 311,\n",
       " 'food': 312,\n",
       " 'called': 313,\n",
       " 'myself': 314,\n",
       " 'little': 315,\n",
       " 'everything': 316,\n",
       " 'ran': 317,\n",
       " 'true': 318,\n",
       " 'asked': 319,\n",
       " 'drink': 320,\n",
       " 'eyes': 321,\n",
       " 'might': 322,\n",
       " \"you'll\": 323,\n",
       " 'hit': 324,\n",
       " 'lie': 325,\n",
       " 'teacher': 326,\n",
       " 'thanks': 327,\n",
       " 'knew': 328,\n",
       " \"you've\": 329,\n",
       " 'boy': 330,\n",
       " 'talking': 331,\n",
       " 'lunch': 332,\n",
       " 'listen': 333,\n",
       " 'real': 334,\n",
       " 'something': 335,\n",
       " 'pay': 336,\n",
       " 'quit': 337,\n",
       " 'hear': 338,\n",
       " 'quiet': 339,\n",
       " 'walk': 340,\n",
       " 'sorry': 341,\n",
       " 'hand': 342,\n",
       " 'seems': 343,\n",
       " 'shut': 344,\n",
       " 'finished': 345,\n",
       " 'gone': 346,\n",
       " 'secret': 347,\n",
       " 'sit': 348,\n",
       " 'hands': 349,\n",
       " 'lawyer': 350,\n",
       " 'wish': 351,\n",
       " 'bring': 352,\n",
       " 'girl': 353,\n",
       " 'best': 354,\n",
       " 'glad': 355,\n",
       " \"couldn't\": 356,\n",
       " 'often': 357,\n",
       " 'every': 358,\n",
       " 'liked': 359,\n",
       " 'child': 360,\n",
       " 'horse': 361,\n",
       " 'fix': 362,\n",
       " 'almost': 363,\n",
       " \"she's\": 364,\n",
       " 'maybe': 365,\n",
       " 'needed': 366,\n",
       " 'working': 367,\n",
       " 'coming': 368,\n",
       " 'lives': 369,\n",
       " 'answer': 370,\n",
       " 'danger': 371,\n",
       " 'getting': 372,\n",
       " 'person': 373,\n",
       " 'fire': 374,\n",
       " 'dead': 375,\n",
       " 'god': 376,\n",
       " 'eating': 377,\n",
       " 'gun': 378,\n",
       " 'doctor': 379,\n",
       " 'someone': 380,\n",
       " 'strange': 381,\n",
       " 'being': 382,\n",
       " 'seen': 383,\n",
       " 'anybody': 384,\n",
       " 'than': 385,\n",
       " 'another': 386,\n",
       " 'kill': 387,\n",
       " 'outside': 388,\n",
       " 'miss': 389,\n",
       " 'young': 390,\n",
       " 'mother': 391,\n",
       " 'hates': 392,\n",
       " 'stole': 393,\n",
       " 'bike': 394,\n",
       " 'afraid': 395,\n",
       " 'week': 396,\n",
       " 'deal': 397,\n",
       " 'if': 398,\n",
       " 'smart': 399,\n",
       " 'point': 400,\n",
       " '2': 401,\n",
       " \"there's\": 402,\n",
       " 'which': 403,\n",
       " 'many': 404,\n",
       " 'tomorrow': 405,\n",
       " 'early': 406,\n",
       " 'red': 407,\n",
       " \"here's\": 408,\n",
       " 'stupid': 409,\n",
       " 'forgot': 410,\n",
       " 'fine': 411,\n",
       " 'next': 412,\n",
       " 'understand': 413,\n",
       " 'kiss': 414,\n",
       " 'drunk': 415,\n",
       " 'dirty': 416,\n",
       " 'heart': 417,\n",
       " 'dinner': 418,\n",
       " 'guys': 419,\n",
       " 'friends': 420,\n",
       " 'warn': 421,\n",
       " 'care': 422,\n",
       " 'drank': 423,\n",
       " 'mad': 424,\n",
       " 'crying': 425,\n",
       " 'married': 426,\n",
       " 'start': 427,\n",
       " 'heard': 428,\n",
       " 'waiting': 429,\n",
       " 'kids': 430,\n",
       " 'tonight': 431,\n",
       " 'caught': 432,\n",
       " 'books': 433,\n",
       " 'whose': 434,\n",
       " 'thing': 435,\n",
       " 'cool': 436,\n",
       " 'lied': 437,\n",
       " 'move': 438,\n",
       " 'night': 439,\n",
       " 'milk': 440,\n",
       " 'check': 441,\n",
       " 'cook': 442,\n",
       " 'music': 443,\n",
       " 'wear': 444,\n",
       " 'works': 445,\n",
       " 'key': 446,\n",
       " 'monday': 447,\n",
       " 'together': 448,\n",
       " 'ugly': 449,\n",
       " 'cut': 450,\n",
       " 'strong': 451,\n",
       " 'joke': 452,\n",
       " 'around': 453,\n",
       " 'scared': 454,\n",
       " 'turned': 455,\n",
       " 'empty': 456,\n",
       " \"how's\": 457,\n",
       " 'apple': 458,\n",
       " 'changed': 459,\n",
       " 'word': 460,\n",
       " 'born': 461,\n",
       " 'happen': 462,\n",
       " 'news': 463,\n",
       " 'perfect': 464,\n",
       " 'shirt': 465,\n",
       " 'inside': 466,\n",
       " 'small': 467,\n",
       " 'trying': 468,\n",
       " 'mind': 469,\n",
       " 'started': 470,\n",
       " 'fish': 471,\n",
       " 'lose': 472,\n",
       " 'set': 473,\n",
       " 'sleepy': 474,\n",
       " 'mean': 475,\n",
       " 'watching': 476,\n",
       " 'owe': 477,\n",
       " 'thirsty': 478,\n",
       " 'fault': 479,\n",
       " 'arrived': 480,\n",
       " 'black': 481,\n",
       " 'bus': 482,\n",
       " 'close': 483,\n",
       " 'children': 484,\n",
       " 'student': 485,\n",
       " 'party': 486,\n",
       " 'into': 487,\n",
       " 'tall': 488,\n",
       " 'tea': 489,\n",
       " 'study': 490,\n",
       " 'shy': 491,\n",
       " 'hey': 492,\n",
       " 'enjoy': 493,\n",
       " 'blame': 494,\n",
       " 'asleep': 495,\n",
       " 'end': 496,\n",
       " 'team': 497,\n",
       " 'lonely': 498,\n",
       " 'shot': 499,\n",
       " 'seem': 500,\n",
       " 'sat': 501,\n",
       " 'truth': 502,\n",
       " 'class': 503,\n",
       " 'family': 504,\n",
       " 'sister': 505,\n",
       " 'keys': 506,\n",
       " 'place': 507,\n",
       " 'story': 508,\n",
       " 'office': 509,\n",
       " 'same': 510,\n",
       " 'ever': 511,\n",
       " 'forget': 512,\n",
       " 'thank': 513,\n",
       " 'waited': 514,\n",
       " 'patient': 515,\n",
       " 'gift': 516,\n",
       " 'once': 517,\n",
       " 'brave': 518,\n",
       " 'sell': 519,\n",
       " 'short': 520,\n",
       " 'careful': 521,\n",
       " \"one's\": 522,\n",
       " 'closed': 523,\n",
       " 'cake': 524,\n",
       " 'beat': 525,\n",
       " 'laughing': 526,\n",
       " 'funny': 527,\n",
       " 'woman': 528,\n",
       " 'chance': 529,\n",
       " 'coat': 530,\n",
       " 'line': 531,\n",
       " 'opened': 532,\n",
       " 'box': 533,\n",
       " 'later': 534,\n",
       " 'things': 535,\n",
       " 'list': 536,\n",
       " 'other': 537,\n",
       " 'else': 538,\n",
       " 'write': 539,\n",
       " 'follow': 540,\n",
       " 'serious': 541,\n",
       " 'slept': 542,\n",
       " 'boss': 543,\n",
       " 'men': 544,\n",
       " 'fell': 545,\n",
       " 'mom': 546,\n",
       " 'town': 547,\n",
       " 'upset': 548,\n",
       " 'uncle': 549,\n",
       " 'began': 550,\n",
       " 'brought': 551,\n",
       " 'amazing': 552,\n",
       " 'finally': 553,\n",
       " 'playing': 554,\n",
       " 'baby': 555,\n",
       " 'smell': 556,\n",
       " \"they'll\": 557,\n",
       " 'became': 558,\n",
       " \"mary's\": 559,\n",
       " 'begin': 560,\n",
       " 'expensive': 561,\n",
       " 'their': 562,\n",
       " 'yesterday': 563,\n",
       " 'poor': 564,\n",
       " 'full': 565,\n",
       " 'duty': 566,\n",
       " 'meat': 567,\n",
       " 'thirty': 568,\n",
       " 'worry': 569,\n",
       " 'sign': 570,\n",
       " 'sad': 571,\n",
       " 'loved': 572,\n",
       " 'without': 573,\n",
       " 'bread': 574,\n",
       " 'kid': 575,\n",
       " 'lying': 576,\n",
       " 'also': 577,\n",
       " 'survive': 578,\n",
       " 'year': 579,\n",
       " 'enemy': 580,\n",
       " 'choice': 581,\n",
       " 'smile': 582,\n",
       " 'pen': 583,\n",
       " 'talked': 584,\n",
       " 'honest': 585,\n",
       " 'mine': 586,\n",
       " 'trouble': 587,\n",
       " 'pizza': 588,\n",
       " 'loser': 589,\n",
       " 'knife': 590,\n",
       " 'clean': 591,\n",
       " 'worried': 592,\n",
       " \"haven't\": 593,\n",
       " 'hold': 594,\n",
       " 'agreed': 595,\n",
       " 'head': 596,\n",
       " 'then': 597,\n",
       " 'liar': 598,\n",
       " 'hurts': 599,\n",
       " 'yes': 600,\n",
       " 'stand': 601,\n",
       " 'rest': 602,\n",
       " 'dream': 603,\n",
       " 'singing': 604,\n",
       " 'break': 605,\n",
       " 'says': 606,\n",
       " 'seemed': 607,\n",
       " 'hour': 608,\n",
       " 'killed': 609,\n",
       " 'train': 610,\n",
       " 'truck': 611,\n",
       " 'each': 612,\n",
       " 'half': 613,\n",
       " 'happened': 614,\n",
       " 'slow': 615,\n",
       " 'touch': 616,\n",
       " 'after': 617,\n",
       " 'bored': 618,\n",
       " 'walked': 619,\n",
       " 'face': 620,\n",
       " 'missed': 621,\n",
       " 'boys': 622,\n",
       " 'dad': 623,\n",
       " 'laughed': 624,\n",
       " 'war': 625,\n",
       " 'or': 626,\n",
       " 'wore': 627,\n",
       " 'normal': 628,\n",
       " 'guilty': 629,\n",
       " 'tough': 630,\n",
       " 'hated': 631,\n",
       " 'fired': 632,\n",
       " 'pain': 633,\n",
       " 'gets': 634,\n",
       " \"it'll\": 635,\n",
       " 'taxi': 636,\n",
       " 'borrow': 637,\n",
       " 'order': 638,\n",
       " \"everyone's\": 639,\n",
       " 'game': 640,\n",
       " 'wrote': 641,\n",
       " 'leaving': 642,\n",
       " 'drinks': 643,\n",
       " 'women': 644,\n",
       " 'window': 645,\n",
       " 'stuff': 646,\n",
       " 'brother': 647,\n",
       " 'contact': 648,\n",
       " 'years': 649,\n",
       " 'drinking': 650,\n",
       " 'taking': 651,\n",
       " 'feels': 652,\n",
       " 'arm': 653,\n",
       " 'offer': 654,\n",
       " 'clear': 655,\n",
       " 'welcome': 656,\n",
       " 'escape': 657,\n",
       " 'picture': 658,\n",
       " 'guess': 659,\n",
       " 'terrible': 660,\n",
       " 'making': 661,\n",
       " 'visit': 662,\n",
       " 'awake': 663,\n",
       " 'worked': 664,\n",
       " 'weak': 665,\n",
       " 'dogs': 666,\n",
       " 'eggs': 667,\n",
       " 'invited': 668,\n",
       " 'stayed': 669,\n",
       " 'blue': 670,\n",
       " 'reading': 671,\n",
       " 'dangerous': 672,\n",
       " 'cute': 673,\n",
       " 'luck': 674,\n",
       " 'act': 675,\n",
       " 'sang': 676,\n",
       " 'hide': 677,\n",
       " 'fed': 678,\n",
       " 'fishing': 679,\n",
       " 'lit': 680,\n",
       " 'quickly': 681,\n",
       " 'illiterate': 682,\n",
       " 'police': 683,\n",
       " 'lift': 684,\n",
       " 'makes': 685,\n",
       " \"what'll\": 686,\n",
       " 'yourselves': 687,\n",
       " 'shoes': 688,\n",
       " 'paper': 689,\n",
       " 'daughter': 690,\n",
       " 'bicycle': 691,\n",
       " 'studied': 692,\n",
       " 'refused': 693,\n",
       " 'probably': 694,\n",
       " 'calm': 695,\n",
       " 'wet': 696,\n",
       " 'forgive': 697,\n",
       " 'hurry': 698,\n",
       " 'voted': 699,\n",
       " 'alive': 700,\n",
       " 'older': 701,\n",
       " 'goodbye': 702,\n",
       " 'jealous': 703,\n",
       " 'explain': 704,\n",
       " 'lazy': 705,\n",
       " 'pick': 706,\n",
       " 'running': 707,\n",
       " 'advice': 708,\n",
       " 'sugar': 709,\n",
       " 'cab': 710,\n",
       " 'special': 711,\n",
       " 'somebody': 712,\n",
       " 'chose': 713,\n",
       " 'played': 714,\n",
       " 'seldom': 715,\n",
       " \"should've\": 716,\n",
       " 'jacket': 717,\n",
       " 'send': 718,\n",
       " 'stopped': 719,\n",
       " 'cash': 720,\n",
       " 'number': 721,\n",
       " 'dark': 722,\n",
       " 'artist': 723,\n",
       " 'tree': 724,\n",
       " 'yours': 725,\n",
       " 'wash': 726,\n",
       " 'behind': 727,\n",
       " \"shouldn't\": 728,\n",
       " \"what're\": 729,\n",
       " 'before': 730,\n",
       " 'hours': 731,\n",
       " 'side': 732,\n",
       " 'continued': 733,\n",
       " 'lock': 734,\n",
       " 'slowly': 735,\n",
       " 'boring': 736,\n",
       " 'vote': 737,\n",
       " 'cooking': 738,\n",
       " 'healthy': 739,\n",
       " 'broken': 740,\n",
       " 'kind': 741,\n",
       " 'high': 742,\n",
       " 'decided': 743,\n",
       " 'raining': 744,\n",
       " 'sent': 745,\n",
       " 'draw': 746,\n",
       " 'unlucky': 747,\n",
       " 'fighting': 748,\n",
       " 'knee': 749,\n",
       " 'calling': 750,\n",
       " 'soup': 751,\n",
       " 'table': 752,\n",
       " 'relax': 753,\n",
       " 'chair': 754,\n",
       " 'white': 755,\n",
       " 'difficult': 756,\n",
       " \"that'll\": 757,\n",
       " 'save': 758,\n",
       " 'cats': 759,\n",
       " 'salad': 760,\n",
       " 'nervous': 761,\n",
       " 'brothers': 762,\n",
       " 'australia': 763,\n",
       " 'legs': 764,\n",
       " 'washed': 765,\n",
       " 'proud': 766,\n",
       " 'beautiful': 767,\n",
       " 'pass': 768,\n",
       " 'garden': 769,\n",
       " 'question': 770,\n",
       " 'mistake': 771,\n",
       " 'worse': 772,\n",
       " 'large': 773,\n",
       " 'wake': 774,\n",
       " 'trap': 775,\n",
       " 'nuts': 776,\n",
       " 'objective': 777,\n",
       " 'map': 778,\n",
       " 'kissed': 779,\n",
       " 'teach': 780,\n",
       " 'cops': 781,\n",
       " 'apologize': 782,\n",
       " 'nose': 783,\n",
       " 'part': 784,\n",
       " 'pray': 785,\n",
       " 'spoke': 786,\n",
       " 'panting': 787,\n",
       " 'six': 788,\n",
       " 'road': 789,\n",
       " 'far': 790,\n",
       " 'company': 791,\n",
       " 'writing': 792,\n",
       " 'details': 793,\n",
       " 'prepared': 794,\n",
       " 'famous': 795,\n",
       " 'skinny': 796,\n",
       " 'heaven': 797,\n",
       " 'feet': 798,\n",
       " 'smiled': 799,\n",
       " 'homework': 800,\n",
       " 'guitar': 801,\n",
       " 'rent': 802,\n",
       " \"you'd\": 803,\n",
       " 'near': 804,\n",
       " 'message': 805,\n",
       " 'sisters': 806,\n",
       " 'excited': 807,\n",
       " 'song': 808,\n",
       " 'fan': 809,\n",
       " \"weren't\": 810,\n",
       " 'health': 811,\n",
       " 'longer': 812,\n",
       " 'bill': 813,\n",
       " 'protect': 814,\n",
       " 'letter': 815,\n",
       " 'double': 816,\n",
       " 'heavy': 817,\n",
       " \"wouldn't\": 818,\n",
       " 'laugh': 819,\n",
       " 'report': 820,\n",
       " 'exam': 821,\n",
       " 'cannot': 822,\n",
       " 'snow': 823,\n",
       " 'days': 824,\n",
       " 'teeth': 825,\n",
       " 'address': 826,\n",
       " 'thought': 827,\n",
       " 'charge': 828,\n",
       " 'decision': 829,\n",
       " 'problems': 830,\n",
       " 'smoke': 831,\n",
       " 'push': 832,\n",
       " 'fly': 833,\n",
       " 'blind': 834,\n",
       " 'hello': 835,\n",
       " 'rice': 836,\n",
       " 'golf': 837,\n",
       " 'retired': 838,\n",
       " 'law': 839,\n",
       " 'dance': 840,\n",
       " 'survived': 841,\n",
       " 'hero': 842,\n",
       " 'canadian': 843,\n",
       " 'walking': 844,\n",
       " 'leg': 845,\n",
       " 'rude': 846,\n",
       " 'feed': 847,\n",
       " 'ignored': 848,\n",
       " 'comes': 849,\n",
       " 'accept': 850,\n",
       " 'boat': 851,\n",
       " 'gas': 852,\n",
       " 'bet': 853,\n",
       " \"nobody's\": 854,\n",
       " 'minute': 855,\n",
       " 'upstairs': 856,\n",
       " 'threw': 857,\n",
       " 'glass': 858,\n",
       " 'proof': 859,\n",
       " 'arrested': 860,\n",
       " 'sleeping': 861,\n",
       " 'takes': 862,\n",
       " 'join': 863,\n",
       " 'prove': 864,\n",
       " 'fit': 865,\n",
       " 'partner': 866,\n",
       " 'swimming': 867,\n",
       " 'note': 868,\n",
       " 'staying': 869,\n",
       " 'rules': 870,\n",
       " 'trip': 871,\n",
       " 'locked': 872,\n",
       " 'moment': 873,\n",
       " 'pulse': 874,\n",
       " 'excuse': 875,\n",
       " 'scary': 876,\n",
       " '2013': 877,\n",
       " 'handle': 878,\n",
       " 'vacation': 879,\n",
       " 'simple': 880,\n",
       " 'hired': 881,\n",
       " 'sound': 882,\n",
       " 'flight': 883,\n",
       " 'park': 884,\n",
       " 'feeling': 885,\n",
       " 'eye': 886,\n",
       " 'hire': 887,\n",
       " 'looking': 888,\n",
       " 'opinion': 889,\n",
       " \"today's\": 890,\n",
       " 'asking': 891,\n",
       " \"hasn't\": 892,\n",
       " 'wearing': 893,\n",
       " 'eaten': 894,\n",
       " 'hi': 895,\n",
       " 'deaf': 896,\n",
       " 'woke': 897,\n",
       " 'sharp': 898,\n",
       " 'rush': 899,\n",
       " 'cruel': 900,\n",
       " 'failed': 901,\n",
       " 'through': 902,\n",
       " 'wealthy': 903,\n",
       " 'talks': 904,\n",
       " 'dress': 905,\n",
       " 'apples': 906,\n",
       " 'second': 907,\n",
       " 'learn': 908,\n",
       " 'homeless': 909,\n",
       " 'bird': 910,\n",
       " 'cars': 911,\n",
       " 'baked': 912,\n",
       " 'pie': 913,\n",
       " 'trusted': 914,\n",
       " 'adopted': 915,\n",
       " 'unhappy': 916,\n",
       " 'exciting': 917,\n",
       " 'fussy': 918,\n",
       " 'floor': 919,\n",
       " 'beard': 920,\n",
       " 'sold': 921,\n",
       " 'flowers': 922,\n",
       " 'city': 923,\n",
       " 'tie': 924,\n",
       " 'punished': 925,\n",
       " 'aunt': 926,\n",
       " 'sounds': 927,\n",
       " 'doors': 928,\n",
       " 'seat': 929,\n",
       " 'wise': 930,\n",
       " 'tongue': 931,\n",
       " 'drove': 932,\n",
       " 'sword': 933,\n",
       " 'adventurous': 934,\n",
       " 'rather': 935,\n",
       " 'driver': 936,\n",
       " 'clever': 937,\n",
       " 'cousin': 938,\n",
       " 'mess': 939,\n",
       " 'straight': 940,\n",
       " 'few': 941,\n",
       " 'having': 942,\n",
       " 'world': 943,\n",
       " 'button': 944,\n",
       " 'hid': 945,\n",
       " 'ice': 946,\n",
       " 'tense': 947,\n",
       " 'goes': 948,\n",
       " 'noticed': 949,\n",
       " 'computer': 950,\n",
       " 'prefer': 951,\n",
       " 'price': 952,\n",
       " 'stolen': 953,\n",
       " 'drives': 954,\n",
       " 'dropped': 955,\n",
       " 'learned': 956,\n",
       " 'kidding': 957,\n",
       " 'until': 958,\n",
       " 'camera': 959,\n",
       " 'extremely': 960,\n",
       " 'stomach': 961,\n",
       " 'cost': 962,\n",
       " 'respect': 963,\n",
       " 'stubborn': 964,\n",
       " 'ago': 965,\n",
       " 'movie': 966,\n",
       " 'carry': 967,\n",
       " 'anymore': 968,\n",
       " 'studying': 969,\n",
       " 'denied': 970,\n",
       " 'possibly': 971,\n",
       " 'thin': 972,\n",
       " 'marry': 973,\n",
       " 'swam': 974,\n",
       " 'cried': 975,\n",
       " 'fair': 976,\n",
       " 'insane': 977,\n",
       " 'confessed': 978,\n",
       " 'hike': 979,\n",
       " 'ship': 980,\n",
       " 'scream': 981,\n",
       " 'morning': 982,\n",
       " 'girls': 983,\n",
       " 'romantic': 984,\n",
       " 'easily': 985,\n",
       " 'grew': 986,\n",
       " 'jokes': 987,\n",
       " 'passed': 988,\n",
       " 'fruit': 989,\n",
       " 'actor': 990,\n",
       " 'escaped': 991,\n",
       " 'correct': 992,\n",
       " 'shame': 993,\n",
       " 'winter': 994,\n",
       " 'stared': 995,\n",
       " 'ambitious': 996,\n",
       " 'expecting': 997,\n",
       " 'genius': 998,\n",
       " 'sweet': 999,\n",
       " 'fake': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx_inputs.get('run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14121 unique output tokens.\n",
      "Max sentence length for Output:  9\n"
     ]
    }
   ],
   "source": [
    "# Tokenize Outputs\n",
    "\n",
    "# don't filter out special characters\n",
    "# otherwise <sos> and <eos> won't appear\n",
    "tokenizer_outputs = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
    "tokenizer_outputs.fit_on_texts(target_texts + target_texts_inputs)\n",
    "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n",
    "target_sequences_input = tokenizer_outputs.texts_to_sequences(target_texts_inputs)\n",
    "\n",
    "# get the word to index mapping for output language\n",
    "word2idx_outputs = tokenizer_outputs.word_index\n",
    "print('Found %s unique output tokens.' % len(word2idx_outputs))\n",
    "\n",
    "# store number of output words for later\n",
    "# remember to add 1 since indexing starts at 1\n",
    "num_words_output = len(word2idx_outputs) + 1\n",
    "\n",
    "# determine maximum length output sequence\n",
    "max_len_target = max(len(s) for s in target_sequences)\n",
    "print(\"Max sentence length for Output: \",max_len_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_inputs.shape: (20000, 7)\n",
      "encoder_inputs[0]: [  0   0   0   0   0   0 244]\n",
      "decoder_inputs[0]: [   2 3067    0    0    0    0    0    0    0]\n",
      "decoder_inputs.shape: (20000, 9)\n",
      "decoder_outputs[0]: [3067    1    0    0    0    0    0    0    0]\n",
      "decoder_outputs.shape: (20000, 9)\n"
     ]
    }
   ],
   "source": [
    "# pad the sequences\n",
    "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
    "print(\"encoder_inputs.shape:\", encoder_inputs.shape)\n",
    "print(\"encoder_inputs[0]:\", encoder_inputs[0])\n",
    "\n",
    "decoder_inputs = pad_sequences(target_sequences_input, maxlen=max_len_target, padding='post')\n",
    "print(\"decoder_inputs[0]:\", decoder_inputs[0])\n",
    "print(\"decoder_inputs.shape:\", decoder_inputs.shape)\n",
    "\n",
    "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding='post')\n",
    "print(\"decoder_outputs[0]:\", decoder_targets[0])\n",
    "print(\"decoder_outputs.shape:\", decoder_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx_outputs[\"<eos>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word2vec model…\n"
     ]
    }
   ],
   "source": [
    "# Load Word Vectors\n",
    "print(\"loading word2vec model…\")\n",
    "word2vec_model = KeyedVectors.load_word2vec_format('C:\\\\Word2Vec_Models\\\\GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVector(str):\n",
    "    if str in word2vec_model:\n",
    "        return word2vec_model[str]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def isInModel(str):\n",
    "    return str in word2vec_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare embedding matrix\n",
    "num_words = min(MAX_NUM_WORDS, len(word2idx_inputs) +1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word2idx_inputs.items():\n",
    "    embedding_vector = getVector(word)\n",
    "    \n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4669, 300)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedding layer\n",
    "embedding_layer = Embedding(\n",
    "  num_words,\n",
    "  EMBEDDING_DIM,\n",
    "  weights=[embedding_matrix],\n",
    "  input_length=max_len_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create targets, since we cannot use sparse\n",
    "# categorical cross entropy when we have sequences\n",
    "decoder_targets_one_hot = np.zeros(\n",
    "  (\n",
    "    len(input_texts),\n",
    "    max_len_target,\n",
    "    num_words_output\n",
    "  ),\n",
    "  dtype='float32'\n",
    ")\n",
    "\n",
    "# assign the values\n",
    "for i, d in enumerate(decoder_targets):\n",
    "    for t, word in enumerate(d):\n",
    "        decoder_targets_one_hot[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 9, 14122)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each target has 9 maximum length and Turkish has \n",
    "# 14122 words in Turkish vocabulary\n",
    "# with 20000 training samples\n",
    "decoder_targets_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Model\n",
    "encoder_inputs_placeholder = Input(shape=(max_len_input,))\n",
    "x = embedding_layer(encoder_inputs_placeholder)\n",
    "\n",
    "encoder = LSTM(LATENT_DIM, return_state=True)\n",
    "encoder_outputs, h, c = encoder(x)\n",
    "\n",
    "# keep only the states to pass into decoder\n",
    "encoder_states = [h, c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder, using [h, c] as initial state.\n",
    "decoder_inputs_placeholder = Input(shape=(max_len_target,))\n",
    "\n",
    "# this word embedding will not use pre-trained vectors\n",
    "# although you could\n",
    "decoder_embedding = Embedding(num_words_output, LATENT_DIM)\n",
    "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
    "\n",
    "# since the decoder is a \"to-many\" model we want to have\n",
    "# return_sequences=True\n",
    "decoder_lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True)\n",
    "\n",
    "decoder_outputs, _, _ = decoder_lstm(\n",
    "  decoder_inputs_x,\n",
    "  initial_state=encoder_states\n",
    ")\n",
    "\n",
    "# final dense layer for predictions\n",
    "# num_words_output = how many words in Turkish language side\n",
    "decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model object\n",
    "model = Model([encoder_inputs_placeholder, decoder_inputs_placeholder], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 7)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 9)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 7, 300)       1400700     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 9, 512)       7230464     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 512), (None, 1665024     embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 9, 512), (No 2099200     embedding_2[0][0]                \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 9, 14122)     7244586     lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 19,639,974\n",
      "Trainable params: 19,639,974\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and train it\n",
    "model.compile(\n",
    "  optimizer='rmsprop',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dtecitak\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/15\n",
      "16000/16000 [==============================] - 220s 14ms/step - loss: 2.6898 - accuracy: 0.6790 - val_loss: 2.8383 - val_accuracy: 0.6506\n",
      "Epoch 2/15\n",
      "16000/16000 [==============================] - 222s 14ms/step - loss: 2.1198 - accuracy: 0.7264 - val_loss: 2.5516 - val_accuracy: 0.6808\n",
      "Epoch 3/15\n",
      "16000/16000 [==============================] - 230s 14ms/step - loss: 1.8494 - accuracy: 0.7546 - val_loss: 2.4073 - val_accuracy: 0.6966\n",
      "Epoch 4/15\n",
      "16000/16000 [==============================] - 240s 15ms/step - loss: 1.6683 - accuracy: 0.7748 - val_loss: 2.3189 - val_accuracy: 0.7092\n",
      "Epoch 5/15\n",
      "16000/16000 [==============================] - 230s 14ms/step - loss: 1.5297 - accuracy: 0.7905 - val_loss: 2.2714 - val_accuracy: 0.7166\n",
      "Epoch 6/15\n",
      "16000/16000 [==============================] - 228s 14ms/step - loss: 1.4140 - accuracy: 0.8046 - val_loss: 2.2657 - val_accuracy: 0.7161\n",
      "Epoch 7/15\n",
      "16000/16000 [==============================] - 238s 15ms/step - loss: 1.3133 - accuracy: 0.8172 - val_loss: 2.2654 - val_accuracy: 0.7175\n",
      "Epoch 8/15\n",
      "16000/16000 [==============================] - 232s 15ms/step - loss: 1.2262 - accuracy: 0.8289 - val_loss: 2.2660 - val_accuracy: 0.7181\n",
      "Epoch 9/15\n",
      "16000/16000 [==============================] - 228s 14ms/step - loss: 1.1542 - accuracy: 0.8396 - val_loss: 2.2738 - val_accuracy: 0.7180\n",
      "Epoch 10/15\n",
      "16000/16000 [==============================] - 248s 16ms/step - loss: 1.0890 - accuracy: 0.8492 - val_loss: 2.2836 - val_accuracy: 0.7171\n",
      "Epoch 11/15\n",
      "16000/16000 [==============================] - 226s 14ms/step - loss: 1.0315 - accuracy: 0.8580 - val_loss: 2.2883 - val_accuracy: 0.7172\n",
      "Epoch 12/15\n",
      "16000/16000 [==============================] - 211s 13ms/step - loss: 0.9836 - accuracy: 0.8655 - val_loss: 2.2917 - val_accuracy: 0.7163\n",
      "Epoch 13/15\n",
      "16000/16000 [==============================] - 212s 13ms/step - loss: 0.9451 - accuracy: 0.8722 - val_loss: 2.3025 - val_accuracy: 0.7175\n",
      "Epoch 14/15\n",
      "16000/16000 [==============================] - 214s 13ms/step - loss: 0.9129 - accuracy: 0.8778 - val_loss: 2.3314 - val_accuracy: 0.7166\n",
      "Epoch 15/15\n",
      "16000/16000 [==============================] - 210s 13ms/step - loss: 0.8823 - accuracy: 0.8823 - val_loss: 2.3359 - val_accuracy: 0.7162\n"
     ]
    }
   ],
   "source": [
    "r = model.fit(\n",
    "  [encoder_inputs, decoder_inputs], decoder_targets_one_hot,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  epochs=EPOCHS,\n",
    "  validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# accuracies\n",
    "plt.plot(r.history['accuracy'], label='acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Save model\n",
    "model.save('MT_S2S.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Make predictions #####\n",
    "# As with the poetry example, we need to create another model\n",
    "# that can take in the RNN state and previous word as input\n",
    "# and accept a T=1 sequence.\n",
    "\n",
    "# The encoder will be stand-alone\n",
    "# From this we will get our initial decoder hidden state\n",
    "encoder_model = Model(encoder_inputs_placeholder, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(LATENT_DIM,))\n",
    "decoder_state_input_c = Input(shape=(LATENT_DIM,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "# decoder_states_inputs = [decoder_state_input_h] # gru\n",
    "\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
    "\n",
    "# this time, we want to keep the states too, to be output\n",
    "# by our sampling model\n",
    "decoder_outputs, h, c = decoder_lstm(\n",
    "  decoder_inputs_single_x,\n",
    "  initial_state=decoder_states_inputs\n",
    ")\n",
    "# decoder_outputs, state_h = decoder_lstm(\n",
    "#   decoder_inputs_single_x,\n",
    "#   initial_state=decoder_states_inputs\n",
    "# ) #gru\n",
    "decoder_states = [h, c]\n",
    "# decoder_states = [h] # gru\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# The sampling model\n",
    "# inputs: y(t-1), h(t-1), c(t-1)\n",
    "# outputs: y(t), h(t), c(t)\n",
    "decoder_model = Model(\n",
    "  [decoder_inputs_single] + decoder_states_inputs, \n",
    "  [decoder_outputs] + decoder_states\n",
    ")\n",
    "\n",
    "# map indexes back into real words\n",
    "# so we can view the results\n",
    "idx2word_eng = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_trans = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1))\n",
    "\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    # NOTE: tokenizer lower-cases all words\n",
    "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "\n",
    "    # if we get this we break\n",
    "    eos = word2idx_outputs['<eos>']\n",
    "\n",
    "    # Create the translation\n",
    "    output_sentence = []\n",
    "    for _ in range(max_len_target):\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "    # output_tokens, h = decoder_model.predict(\n",
    "    #     [target_seq] + states_value\n",
    "    # ) # gru\n",
    "\n",
    "        # Get next word\n",
    "        idx = np.argmax(output_tokens[0, 0, :])\n",
    "\n",
    "        # End sentence of EOS\n",
    "        if eos == idx:\n",
    "            break\n",
    "\n",
    "        word = ''\n",
    "        if idx > 0:\n",
    "            word = idx2word_trans[idx]\n",
    "            output_sentence.append(word)\n",
    "\n",
    "        # Update the decoder input\n",
    "        # which is just the word just generated\n",
    "        target_seq[0, 0] = idx\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "        # states_value = [h] # gru\n",
    "\n",
    "    return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input: My neighbor is crazy.\n",
      "Translation: karım çok ben benim verdi.\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input: I have a maid.\n",
      "Translation: bir kardeşim var.\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input: Tom sings at church.\n",
      "Translation: tom şarkı şarkı söyler.\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input: He begged for his life.\n",
      "Translation: onun adamdır.\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input: The rain has stopped.\n",
      "Translation: yağmur yağmur yağmur\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input: Now's my chance.\n",
      "Translation: şimdi benim şimdi değil.\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input: Lighten up, guys.\n",
      "Translation: siz de tom'un bizimle tut.\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input: Ask Tom what he wants.\n",
      "Translation: tom'a ne tom'a sor.\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input: Tom closed it.\n",
      "Translation: tom kapattı.\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input: How's your mother, Tom?\n",
      "Translation: senin tom'a nasıl?\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input: Tom can't stand up.\n",
      "Translation: tom ayağa ayağa kadar burada\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input: I saw Tom wink at you.\n",
      "Translation: tom'u için tom'u gördüm.\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input: Is this my wine?\n",
      "Translation: bu benim şarabım mı?\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input: Let's not do it again.\n",
      "Translation: onu yapmak bir yapalım.\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input: We're about to start.\n",
      "Translation: biz şimdi kızgın\n",
      "Continue? [Y/n]n\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Do some test translations\n",
    "    i = np.random.choice(len(input_texts))\n",
    "    input_seq = encoder_inputs[i:i+1]\n",
    "    translation = decode_sequence(input_seq)\n",
    "    \n",
    "    print('-')\n",
    "    print('Input:', input_texts[i])\n",
    "    print('Translation:', translation)\n",
    "\n",
    "    ans = input(\"Continue? [Y/n]\")\n",
    "    if ans and ans.lower().startswith('n'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
